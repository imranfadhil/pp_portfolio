{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from quick_pp.objects import Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Steps to create project\n",
    "1. Run the next cell.\n",
    "2. Specify the example either clastic or carbonate.\n",
    "3. MOCK.qppp project will be saved in notebooks\\data\\04_project folder.\n",
    "\n",
    "* Note that the required curves in the LAS files are 'GR', 'RT', 'NPHI', 'RHOB'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'data/'\n",
    "filenames = []\n",
    "for root, dirs, files in os.walk(data_path):\n",
    "    for file in files:\n",
    "        filenames.append(os.path.join(root, file)) if file.endswith('.las') and not 'seismic' in root  else None\n",
    "print(filenames)\n",
    "\n",
    "project_name = \"VOLVE\"\n",
    "project = Project(name=project_name)\n",
    "project.read_las(filenames)\n",
    "# clear_output()               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process core data\n",
    "data = project.get_all_data()\n",
    "remove_rows = (\n",
    "    (data.WELL_NAME == '15-9-19-SR') & ((data.DEPTH < 560) | (data.DEPTH > 4590))\n",
    ")\n",
    "merged_df = data[~remove_rows].copy()\n",
    "\n",
    "merged_core_df = pd.DataFrame()\n",
    "for well_name, well_data in data.groupby('WELL_NAME'):\n",
    "    if well_name in ['15-9-19-A', '15-9-19-BT2']:\n",
    "        core_data = pd.read_excel(rf\"data\\{well_name}_RCA.xls\", skiprows=3).iloc[1:]\n",
    "        core_data['WELL_NAME'] = well_name\n",
    "        core_data['DEPTH'] = pd.to_numeric(core_data['Depth'], errors='coerce')\n",
    "        core_data['CPORE'] = pd.to_numeric(core_data['Por., hor.'], errors='coerce') / 100\n",
    "        core_data['CPERM'] = pd.to_numeric(core_data['Kl, hor'], errors='coerce')\n",
    "        merged_core_df = pd.concat([merged_core_df, core_data])\n",
    "\n",
    "        # Merge with well logs\n",
    "        temp_df = pd.merge_asof(well_data, core_data[['DEPTH', 'CPORE', 'CPERM']],\n",
    "                                direction='nearest', on='DEPTH', tolerance=0.1524 / 2)\n",
    "        merged_df.loc[merged_df.WELL_NAME == well_name, ['CPORE', 'CPERM']] = temp_df[['CPORE', 'CPERM']]\n",
    "\n",
    "merged_core_df.to_csv(r'data\\merged_core_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process facies data\n",
    "merged_facies_df = pd.DataFrame()\n",
    "for well_name, well_data in merged_df.groupby('WELL_NAME'):\n",
    "    if well_name in ['15-9-19-A', '15-9-19-BT2', '15-9-19-SR']:\n",
    "        facies_df = pd.read_excel(rf\"data\\{well_name}_Facies.xlsx\")\n",
    "        facies_df['WELL_NAME'] = well_name\n",
    "        facies_df['TOP_DEPTH'] = pd.to_numeric(facies_df['* Top Depth (meters)'], errors='coerce')\n",
    "        facies_df['BASE_DEPTH'] = pd.to_numeric(facies_df['* Base Depth (meters)'], errors='coerce')\n",
    "        facies_df['LITHOFACIES'] = facies_df['Litho Class']\n",
    "        merged_facies_df = pd.concat([merged_facies_df, facies_df])\n",
    "\n",
    "expanded_rows = []\n",
    "for index, row in merged_facies_df.iterrows():\n",
    "    # Define the depth range for the current row. \n",
    "    # np.arange is great for this, especially with floating point steps.\n",
    "    # We add a small epsilon to the stop value to make sure it's inclusive.\n",
    "    depth_range = np.arange(row['TOP_DEPTH'], row['BASE_DEPTH'] + 0.5, 0.5)\n",
    "    \n",
    "    for depth in depth_range:\n",
    "        expanded_rows.append({\n",
    "            'WELL_NAME': row['WELL_NAME'],\n",
    "            'DEPTH': depth,\n",
    "            'LITHOFACIES': row['LITHOFACIES']\n",
    "        })\n",
    "merged_facies_df = pd.DataFrame(expanded_rows).drop_duplicates(['WELL_NAME', 'DEPTH', 'LITHOFACIES'])\n",
    "merged_facies_df = merged_facies_df.replace({\n",
    "    'UNKNOWN': np.nan, 'UNDEFINED': np.nan\n",
    "})\n",
    "merged_facies_df.to_csv(r'data\\merged_facies_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process zones\n",
    "tops_df = pd.read_excel(rf\"data\\strat_litho_wellbore.xlsx\")\n",
    "tops_df['WELL_NAME'] = tops_df['Wellbore name'].str.replace('/', '-').str.replace(' ', '-')\n",
    "for well_name, well_data in merged_df.groupby('WELL_NAME'):\n",
    "    marker_df = tops_df[tops_df.WELL_NAME == well_name].copy()\n",
    "    marker_df['DEPTH'] = marker_df['Top depth [m]'].astype('float')\n",
    "    marker_df['ZONES'] = marker_df['Lithostrat. unit']\n",
    "\n",
    "    # Merge with well logs\n",
    "    temp_df = pd.merge_asof(well_data, marker_df[['DEPTH', 'ZONES']],\n",
    "                            direction='nearest', on='DEPTH', tolerance=0.1524 / 2)\n",
    "    merged_df.loc[merged_df.WELL_NAME == well_name, ['ZONES']] = temp_df[['ZONES']]\n",
    "merged_df['ZONES'] = merged_df.ZONES.ffill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process TVDSS\n",
    "import wellpathpy as wpp\n",
    "\n",
    "well_survey = pd.read_csv(r\"data\\VOLVE_15-9_Surveys.csv\")[\n",
    "    ['MD (m RKB)', 'Inc (deg)', 'Azim (deg)', 'UTM E/W (m)', 'UTM N/S (m)', 'TVD (m RKB)', 'WELL_NAME']\n",
    "]\n",
    "well_survey.columns = ['md', 'incl', 'azim', 'x', 'y', 'z', 'WELL_NAME']\n",
    "for well_name, well_data in merged_df.groupby('WELL_NAME'):\n",
    "    coords = well_survey[well_survey.WELL_NAME == well_name]\n",
    "    dev_survey = wpp.deviation(coords['md'], coords['incl'], coords['azim'])\n",
    "    tvd = dev_survey.minimum_curvature().resample(well_data.DEPTH.values).depth\n",
    "    mask = (merged_df.WELL_NAME == well_name)\n",
    "\n",
    "    print(well_name, well_data.shape, len(tvd))\n",
    "    print(sum(mask))\n",
    "\n",
    "    merged_df.loc[mask, 'TVD'] = tvd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge with well logs\n",
    "for well_name, well_data in merged_df.groupby('WELL_NAME'):\n",
    "    facies_df = merged_facies_df[merged_facies_df.WELL_NAME == well_name].sort_values('DEPTH').drop(columns='WELL_NAME')\n",
    "    well_data = well_data.sort_values('DEPTH')\n",
    "    temp_df = pd.merge_asof(well_data, facies_df,\n",
    "                            direction='nearest', on='DEPTH', tolerance=0.1524 / 2)\n",
    "    merged_df.loc[merged_df.WELL_NAME == well_name, 'LITHOFACIES'] = temp_df['LITHOFACIES']\n",
    "\n",
    "# Save the update data to the project\n",
    "project.update_data(merged_df)\n",
    "project.save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pp_portfolio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
